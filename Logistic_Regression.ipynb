{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Theoretical Questions"
      ],
      "metadata": {
        "id": "FNPob1NybJ4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Logistic Regression, and how does it differ from Linear Regression?"
      ],
      "metadata": {
        "id": "9YeeegbMbP5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Logistic Regression is a statistical model used for binary classification. It predicts the probability that an instance belongs to a particular class. Despite the name \"regression,\" it's a classification algorithm."
      ],
      "metadata": {
        "id": "lsMqaCnGGDQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is the mathematical equation of Logistic Regression?\n"
      ],
      "metadata": {
        "id": "c1cgtt4ucqbI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> A statistical model typically used to model a binary dependent variable with the help of logistic function. Another name for the logistic function is a sigmoid function and is given by\n",
        "\n",
        "This function assists the logistic regression model to squeeze the values from (-k,k) to (0,1). Logistic regression is majorly used for binary classification tasks; however, it can be used for multiclass classification"
      ],
      "metadata": {
        "id": "dYcDworsGiKv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Why do we use the Sigmoid function in Logistic Regression?\n"
      ],
      "metadata": {
        "id": "5z85TwM4cmji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Probability Output: The primary goal of Logistic Regression is to predict the probability that an instance belongs to a specific class (typically the positive class). The sigmoid function takes any real-valued input and squashes it into a range between 0 and 1. This range is perfect for representing probabilities, where 0 indicates no chance and 1 indicates absolute certainty.\n",
        "\n",
        "Transformation for Binary Classification: Linear Regression outputs a continuous value that can range from negative infinity to positive infinity. However, for binary classification, we need an output that can be interpreted as a probability of belonging to one of two classes. The sigmoid function provides this transformation, making the output suitable for classification tasks.\n",
        "\n",
        "Differentiability: The sigmoid function is differentiable, which is crucial for training the model using gradient-based optimization algorithms like gradient descent. These algorithms require calculating the gradient of the cost function with respect to the model parameters (coefficients), and the differentiability of the sigmoid function allows for this calculation.\n",
        "\n",
        "Interpretation: The S-shaped curve of the sigmoid function provides a smooth transition between the two classes. As the linear combination of features increases, the output of the sigmoid function approaches 1 (indicating higher probability of the positive class), and as it decreases, the output approaches 0 (indicating higher probability of the negative class). This provides a clear and intuitive interpretation of the model's predictions as probabilities."
      ],
      "metadata": {
        "id": "ZAEgI_vVGr82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is the cost function of Logistic Regression?"
      ],
      "metadata": {
        "id": "w4QcZTfmcvta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> The most common cost function used in Logistic Regression is the Log Loss or Binary Cross-Entropy cost function.\n",
        "\n",
        "The goal of this cost function is to penalize the model more heavily when it makes confident but incorrect predictions. It's designed to be minimized during the training process."
      ],
      "metadata": {
        "id": "F1Kxydc3Gz0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What is Regularization in Logistic Regression? Why is it needed?"
      ],
      "metadata": {
        "id": "SgBYUkB3cyYi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Regularization in Logistic Regression is a technique used to prevent overfitting. Overfitting occurs when a model learns the training data too well, including the noise and outliers, which can lead to poor performance on new, unseen data [1, 2]. Regularization methods modify the learning process to limit the flexibility of the model and improve its ability to generalize to new datasets"
      ],
      "metadata": {
        "id": "GYtR0bZlG66l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Explain the difference between Lasso, Ridge, and Elastic Net regression?"
      ],
      "metadata": {
        "id": "ZqTqmVZVc3Dv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> While Logistic Regression is used for classification, the concepts of Lasso, Ridge, and Elastic Net are forms of regularization that can be applied to both linear regression and logistic regression. Here's how they differ:\n",
        "\n",
        "These methods add a penalty term to the cost function during the training process to discourage overly large coefficients. The type of penalty determines the specific regularization technique."
      ],
      "metadata": {
        "id": "g92-xNKWHC-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. When should we use Elastic Net instead of Lasso or Ridge?"
      ],
      "metadata": {
        "id": "6HWs7Vu4c2zj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> When you have a large number of features: In datasets with a high number of features, Elastic Net can be beneficial because it combines the feature selection ability of Lasso with the ability of Ridge to handle correlated predictors.\n",
        "\n",
        "When features are highly correlated: If you have groups of highly correlated features, Lasso tends to arbitrarily select only one feature from the group and shrink the coefficients of the others to zero. Ridge will shrink the coefficients of all correlated features towards zero but not necessarily to zero. Elastic Net, on the other hand, tends to select all features within a highly correlated group together. This can be advantageous when all features in a group are truly relevant to the outcome."
      ],
      "metadata": {
        "id": "829nZ9aoHJpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is the impact of the regularization parameter (Î») in Logistic Regression?"
      ],
      "metadata": {
        "id": "QI9gfsiAc-7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> In Logistic Regression (and other regularized models), the regularization parameter, often denoted by $\\lambda$$\\lambda$ (lambda) or C (in libraries like scikit-learn, where C is the inverse of $\\lambda$$\\lambda$), has a significant impact on the model's behavior:"
      ],
      "metadata": {
        "id": "PyLdgIfUHSdG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What are the key assumptions of Logistic Regression?"
      ],
      "metadata": {
        "id": "SoXMnbf2dBo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Dependent Variable is Binary or Ordinal: Logistic regression is typically used for binary classification problems where the dependent variable has two outcomes (e.g., yes/no, 0/1). It can also be extended for multiclass classification (ordinal logistic regression), but the basic form assumes a binary outcome.\n",
        "\n",
        "Independence of Observations: The observations in the dataset should be independent of each other.\n",
        "\n",
        "No Multicollinearity: There should be little to no multicollinearity among the independent variables. Multicollinearity occurs when independent variables are highly correlated with each other, which can make it difficult to interpret the individual coefficients and can lead to unstable model estimates.\n",
        "\n",
        "Linearity of Log Odds: Logistic Regression assumes a linear relationship between the independent variables and the log odds of the dependent variable. This is different from Linear Regression, which assumes a linear relationship between the independent variables and the dependent variable itself. The log odds are the logarithm of the odds of the event occurring, which is $\\log(\\frac{P(Y=1|X)}{1 - P(Y=1|X)})$$\\log(\\frac{P(Y=1|X)}{1 - P(Y=1|X)})$.\n",
        "\n",
        "Large Sample Size: Logistic Regression generally requires a relatively large sample size to ensure stable and reliable coefficient estimates."
      ],
      "metadata": {
        "id": "xJocjpAkHalI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are some alternatives to Logistic Regression for classification tasks?\n",
        "\n"
      ],
      "metadata": {
        "id": "mYs0jPk6dEtt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Neural Networks: These are a class of machine learning models inspired by the structure of the human brain. They consist of interconnected nodes (neurons) organized in layers. Neural networks can learn complex non-linear relationships between features and the target variable, making them powerful for various classification problems.\n",
        "\n",
        "Support Vector Machines (SVM): SVMs are supervised learning models used for both classification and regression. For classification, SVMs aim to find an optimal hyperplane that separates different classes in the feature space with the largest possible margin.\n",
        "\n",
        "Decision Trees (CART): Classification and Regression Trees (CART) are non-parametric supervised learning methods. They work by recursively partitioning the data based on feature values to create a tree-like structure of decisions. Each leaf node in the tree represents a class label."
      ],
      "metadata": {
        "id": "uRU4lwHzHgDC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What are Classification Evaluation Metrics?\n"
      ],
      "metadata": {
        "id": "OF_BAs1-dKUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Classification evaluation metrics are quantitative measures used to assess the performance of a classification model. They provide a way to understand how well a model is making predictions on a given dataset. Here are some common classification evaluation metrics:\n",
        "\n",
        "Accuracy: This is the most straightforward metric and represents the proportion of correctly classified instances out of the total number of instances."
      ],
      "metadata": {
        "id": "UE1W1CUVQBit"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. How does class imbalance affect Logistic Regression?"
      ],
      "metadata": {
        "id": "bi6tEbjUdNCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> When dealing with imbalanced data, a Logistic Regression model (trained without any specific handling of the imbalance) tends to be biased towards the majority class. This is because the model aims to minimize the overall error (often measured by accuracy or Log Loss), and simply predicting the majority class for most instances can achieve a relatively low error rate on the training data"
      ],
      "metadata": {
        "id": "6kgB1IKuQH7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What is Hyperparameter Tuning in Logistic Regression?\n"
      ],
      "metadata": {
        "id": "XgirfZY5dP8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=>  Hyperparameter Tuning in Logistic Regression is the process of finding the best values for the model's hyperparameters to optimize its performance.\n",
        "\n",
        "What are Hyperparameters?\n",
        "\n",
        "Hyperparameters are parameters that are not learned from the data during the training process but are set before training begins. They control the behavior and structure of the model. In Logistic Regression, common hyperparameters"
      ],
      "metadata": {
        "id": "-FVBW0T4QOwz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What are different solvers in Logistic Regression? Which one should be used?\n"
      ],
      "metadata": {
        "id": "bQOmKTBodSYs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Solvers are algorithms used to find the optimal values for the coefficients (weights) of the Logistic Regression model by minimizing the cost function (typically Log Loss or Binary Cross-Entropy). Different solvers use different optimization strategies and have varying computational characteristics."
      ],
      "metadata": {
        "id": "ONIipBLAQULa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. How is Logistic Regression extended for multiclass classification?\n"
      ],
      "metadata": {
        "id": "oxaKidq_dUUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> One-vs-Rest (OvR) or One-vs-All (OvA):\n",
        "\n",
        "How it works: This strategy involves training a separate binary Logistic Regression model for each class. For a dataset with K classes, K binary classifiers are trained. Each classifier is trained to distinguish one class (the \"one\") from all the other classes (the \"rest\").\n",
        "Prediction: To classify a new instance, each of the K classifiers predicts the probability that the instance belongs to its corresponding class. The instance is then assigned to the class for which the classifier outputs the highest probability [1].\n",
        "\n",
        "Advantages: Relatively simple to implement, computationally efficient for a large number of classes compared to OvO in some cases.\n",
        "Disadvantages: Can suffer from imbalanced datasets for each binary classifier (the \"rest\" class can be much larger than the \"one\" class). The probability scores from different classifiers may not be directly comparable.\n",
        "Multinomial Logistic Regression (Softmax Regression):\n",
        "\"Multinomial: Where the target variable has three or more possible classes\" [2] in the context of types of logistic regression.\n",
        "Advantages: Provides well-calibrated probability estimates across classes. Can be more efficient than OvR in some cases.\n",
        "Disadvantages: Can be more computationally expensive to train than OvR for a very large number of classes."
      ],
      "metadata": {
        "id": "GdnDNTQiQb85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What are the advantages and disadvantages of Logistic Regression?\n"
      ],
      "metadata": {
        "id": "0a-8dt4ZdYqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Simplicity and Interpretability: Logistic Regression is a relatively simple and easy-to-understand algorithm. The coefficients learned by the model can be interpreted in terms of the change in the log odds of the dependent variable for a one-unit change in the independent variable [1]. This interpretability makes it a good choice when you need to understand the relationship between features and the outcome.\n",
        "\n",
        "\n",
        "Not Suitable for Non-Linear Relationships: Logistic Regression is primarily a linear model (in the log odds space) and may not perform well on datasets with complex non-linear relationships between features and the target variable. More complex models like Neural Networks or SVMs with non-linear kernels might be better suited for such cases [1]."
      ],
      "metadata": {
        "id": "W-JJDpHjQmca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What are some use cases of Logistic Regression?\n"
      ],
      "metadata": {
        "id": "-I5IikY3ddvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Fraud Detection: Logistic regression models can help teams identify data anomalies, which are predictive of fraud [1]. By analyzing various features related to transactions (e.g., amount, location, frequency), a logistic regression model can predict the probability of a transaction being fraudulent.\n",
        "Disease Prediction: In medicine, this analytics approach can be used to predict the likelihood of disease or illness for a given population [1]. Based on patient characteristics, medical history, and test results, a logistic regression model can estimate the probability of developing a particular disease.\n",
        "Credit Risk Assessment: Predicting the likelihood of a loan applicant defaulting on a loan. Based on factors like credit score, income, and debt, a logistic regression model can assess the risk of default."
      ],
      "metadata": {
        "id": "tW2D9_R1Qv-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What is the difference between Softmax Regression and Logistic Regression?\n"
      ],
      "metadata": {
        "id": "_nj2IeQKdfz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=>\n",
        "* Logistic Regression (Binary):\n",
        "\n",
        "Purpose: Used for binary classification problems, where the target variable has exactly two classes (e.g., 0 or 1, yes or no).\n",
        "Output: Outputs a single probability score between 0 and 1, representing the probability of an instance belonging to the positive class (usually class 1).\n",
        "Function: Uses the sigmoid function to map the linear combination of features to a probability.\n",
        "Cost Function: Typically uses Binary Cross-Entropy (Log Loss).\n",
        "* Softmax Regression (Multinomial Logistic Regression):\n",
        "\n",
        "Purpose: Used for multiclass classification problems, where the target variable has three or more classes [2].\n",
        "Output: Outputs a probability distribution over all the classes. For each instance, it provides a probability score for each class, and these probabilities sum up to 1.\n",
        "Function: Uses the softmax function to map the linear combination of features to a probability distribution over the classes. The softmax function is a generalization of the sigmoid function to multiple classes.\n",
        "Cost Function: Typically uses Categorical Cross-Entropy."
      ],
      "metadata": {
        "id": "Rs1TxPZbQ4fR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n"
      ],
      "metadata": {
        "id": "jFgKXGjBdiB2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Simplicity and Interpretability: OvR is conceptually simpler to understand as it trains multiple independent binary classifiers. This can sometimes make the individual classifiers easier to interpret.\n",
        "Computational Efficiency for a Very Large Number of Classes: In some cases, especially with certain implementations or when the cost of training a single model with many output nodes (as in Softmax) becomes prohibitive, training multiple independent binary classifiers with OvR might be computationally more efficient."
      ],
      "metadata": {
        "id": "SD0vvHc_RFQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. How do we interpret coefficients in Logistic Regression?"
      ],
      "metadata": {
        "id": "72OF1EHndkJZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> In Logistic Regression, the coefficients  represent the change in the log odds of the dependent variable for a one-unit change in the corresponding independent variable, assuming all other independent variables are held constant."
      ],
      "metadata": {
        "id": "L9ICLmAxRHaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Practical Questions"
      ],
      "metadata": {
        "id": "sY2N2hi6dnuN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy"
      ],
      "metadata": {
        "id": "xzO7iH5uduiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRj7r5XSfzNA",
        "outputId": "5c4d9e79-ac86-4da9-ea30-7c8863f7363e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy\n"
      ],
      "metadata": {
        "id": "or6vJHnJemqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "jdASgMsuf41j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients\n"
      ],
      "metadata": {
        "id": "SAlzkAj5ep4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear')\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "print(\"\\nModel Coefficients:\")\n",
        "print(model.coef_)"
      ],
      "metadata": {
        "id": "Rmk5hmgEf5d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')\n"
      ],
      "metadata": {
        "id": "kXgB8Ot7esnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "FWjUoiW7f58M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'\n"
      ],
      "metadata": {
        "id": "Oq-B-h17evWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear')\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy (OvR): {accuracy}\")"
      ],
      "metadata": {
        "id": "_58nRX4_f7hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy\n"
      ],
      "metadata": {
        "id": "juAO_WATezlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
        "print(f\"Model Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "8O2K2n5qf8IG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy\n"
      ],
      "metadata": {
        "id": "5ovq3pmpe3M-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies = []\n",
        "\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = LogisticRegression(solver='liblinear')\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "average_accuracy = sum(accuracies) / len(accuracies)\n",
        "print(f\"Average Accuracy: {average_accuracy}\")"
      ],
      "metadata": {
        "id": "ga5zGrPXf86k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy.\n"
      ],
      "metadata": {
        "id": "RT_aqjb5e7Oe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "K5jLBkUzf9Zf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy\n"
      ],
      "metadata": {
        "id": "3SjlOC--e_A7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "\n",
        "param_dist = {\n",
        "    'C': np.logspace(-4, 4, 20),\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "\n",
        "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=10, cv=5, random_state=42, n_jobs=-1)\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with Best Parameters: {accuracy}\")"
      ],
      "metadata": {
        "id": "sYRBWNFrTD9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy\n"
      ],
      "metadata": {
        "id": "lfhmUftFfB-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "base_estimator = LogisticRegression(solver='liblinear')\n",
        "\n",
        "model = OneVsOneClassifier(base_estimator)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy (OvO): {accuracy}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P6qcra66f-bN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification\n"
      ],
      "metadata": {
        "id": "n_CRWWNIfEbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n"
      ],
      "metadata": {
        "id": "i7Fru4qBf-5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score\n"
      ],
      "metadata": {
        "id": "m-ZWYXqWfHQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy}\")\n",
        "\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")"
      ],
      "metadata": {
        "id": "vmaGCS_zf_g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance\n"
      ],
      "metadata": {
        "id": "HX67LjxLfJiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5,\n",
        "                           n_classes=2, n_clusters_per_class=1, weights=[0.95, 0.05],\n",
        "                           flip_y=0, random_state=42)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "print(\"Training Logistic Regression without class weights:\")\n",
        "model_no_weights = LogisticRegression(solver='liblinear')\n",
        "model_no_weights.fit(X_train, y_train)\n",
        "y_pred_no_weights = model_no_weights.predict(X_test)\n",
        "\n",
        "accuracy_no_weights = accuracy_score(y_test, y_pred_no_weights)\n",
        "print(f\"Accuracy without class weights: {accuracy_no_weights}\")\n",
        "print(\"Classification Report without class weights:\")\n",
        "print(classification_report(y_test, y_pred_no_weights))\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nTraining Logistic Regression with class weights:\")\n",
        "\n",
        "model_with_weights = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
        "model_with_weights.fit(X_train, y_train)\n",
        "y_pred_with_weights = model_with_weights.predict(X_test)\n",
        "\n",
        "accuracy_with_weights = accuracy_score(y_test, y_pred_with_weights)\n",
        "print(f\"Accuracy with class weights: {accuracy_with_weights}\")\n",
        "print(\"Classification Report with class weights:\")\n",
        "print(classification_report(y_test, y_pred_with_weights))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FS8f6OdtUAI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance\n"
      ],
      "metadata": {
        "id": "PRK0KmQZfMf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv('titanic.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Ensure 'titanic.csv' is uploaded to your Colab environment.\")\n",
        "    exit()\n",
        "\n",
        "df = df[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']].copy()\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df['Age'] = imputer.fit_transform(df[['Age']])\n",
        "\n",
        "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
        "\n",
        "le_sex = LabelEncoder()\n",
        "df['Sex'] = le_sex.fit_transform(df['Sex'])\n",
        "\n",
        "df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\n",
        "\n",
        "X = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(solver='liblinear', max_iter=1000)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "KdaQ5sN8gArv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling\n"
      ],
      "metadata": {
        "id": "uMQ_6AzdfPYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy (Scaled): {accuracy_scaled}\")\n",
        "\n",
        "accuracy_unscaled = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy (Unscaled): {accuracy_unscaled}\")"
      ],
      "metadata": {
        "id": "rRQJjMybgBMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score\n"
      ],
      "metadata": {
        "id": "VEJ1Bb_SfUC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy}\")\n",
        "\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(f\"ROC-AUC Score: {roc_auc}\")"
      ],
      "metadata": {
        "id": "DvrmZOuOgBt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy\n"
      ],
      "metadata": {
        "id": "BrB7FxV_fWW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(solver='liblinear', C=0.5)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "jZghM_HhgCPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Write a Python program to train Logistic Regression and identify important features based on model coefficients\n"
      ],
      "metadata": {
        "id": "Kd6O9PJofZ15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "feature_names = iris.feature_names\n",
        "\n",
        "\n",
        "X_binary = X[y != 2]\n",
        "y_binary = y[y != 2]\n",
        "feature_names_binary = feature_names[:2]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "coefficients = model.coef_[0]\n",
        "feature_importance = pd.DataFrame({'Feature': feature_names_binary, 'Coefficient': coefficients})\n",
        "\n",
        "feature_importance['Abs_Coefficient'] = abs(feature_importance['Coefficient'])\n",
        "feature_importance = feature_importance.sort_values(by='Abs_Coefficient', ascending=False)\n",
        "\n",
        "print(\"Feature Importance based on Logistic Regression Coefficients (Sorted by Absolute Magnitude):\")\n",
        "print(feature_importance)\n"
      ],
      "metadata": {
        "id": "UUmogrB4U2nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Write a Python program to train Logistic Regression and evaluate its performance using Cohenâs Kappa Score\n"
      ],
      "metadata": {
        "id": "PTD407W4fcfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "24RlzjfdgDQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classificatio\n"
      ],
      "metadata": {
        "id": "oHCU4WxDffUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, marker='.', label='Logistic Regression')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve for Logistic Regression')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zef9R9sYgDsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy\n"
      ],
      "metadata": {
        "id": "jAgnwKtffh55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Model Accuracy ({solver}): {accuracy}\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "d42gEFcNgEJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC)\n"
      ],
      "metadata": {
        "id": "xNm6e1Jbfkry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_binary = X[y != 2]\n",
        "y_binary = y[y != 2]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy}\")\n",
        "\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc}\")\n"
      ],
      "metadata": {
        "id": "ZzeSGDZEgE07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling\n"
      ],
      "metadata": {
        "id": "tN0c2kLJfqRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_unscaled = LogisticRegression(solver='liblinear')\n",
        "model_unscaled.fit(X_train, y_train)\n",
        "y_pred_unscaled = model_unscaled.predict(X_test)\n",
        "accuracy_unscaled = accuracy_score(y_test, y_pred_unscaled)\n",
        "print(f\"Model Accuracy (Unscaled): {accuracy_unscaled}\")\n"
      ],
      "metadata": {
        "id": "qYXok5NVgFYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation\n"
      ],
      "metadata": {
        "id": "Hg2hAjuAftfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "1LSg5iWpgFzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions."
      ],
      "metadata": {
        "id": "VZygC2rHfwUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for the above Ques.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_initial = model.predict(X_test)\n",
        "accuracy_initial = accuracy_score(y_test, y_pred_initial)\n",
        "print(f\"Model Accuracy (after initial training): {accuracy_initial}\")\n",
        "\n",
        "\n",
        "model_filename = 'logistic_regression_model.joblib'\n",
        "\n",
        "joblib.dump(model, model_filename)\n",
        "print(f\"\\nModel saved to {model_filename}\")\n",
        "\n",
        "\n",
        "if os.path.exists(model_filename):\n",
        "\n",
        "    loaded_model = joblib.load(model_filename)\n",
        "    print(f\"\\nModel loaded from {model_filename}\")\n",
        "\n",
        "    y_pred_loaded = loaded_model.predict(X_test)\n",
        "\n",
        "\n",
        "    accuracy_loaded = accuracy_score(y_test, y_pred_loaded)"
      ],
      "metadata": {
        "id": "h2xHT8JugGTo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}